{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from brain_score import time_series_ridge_cv_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "design_mat = scipy.io.loadmat(\"./design_matrix/activation_design_mat_1Hz/v25/design_mat_after_pca.mat\")\n",
    "design_mat[\"pc_mat_1\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_mat_full = [design_mat[\"pc_mat_1\"], np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_2\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_3\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_4\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_5\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_6\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_7\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_8\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_9\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_10\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_11\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_12\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_13\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_14\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_15\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_16\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_17\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_18\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_19\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_20\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_21\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_22\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_23\"]], axis=1), np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_24\"]], axis=1),\n",
    "                   np.concatenate([design_mat[\"pc_mat_1\"], design_mat[\"pc_mat_25\"]], axis=1),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 20, (98, 20, 25))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the folder containing the .mat files\n",
    "folder_path = \"./Data/v3_hbdata/extracted_hbo_data_full/TD\"  # Change this to your actual path\n",
    "# folder_path = \"./Data/v3_hbdata/extracted_hbo_data_full/WD\"  # Change this to your actual path\n",
    "\n",
    "# Get list of .mat files\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.mat')]\n",
    "\n",
    "num_files = len(files)\n",
    "# num_channels = 20  # Each Y has 20 columns\n",
    "num_channels = 32  # Each Y has 32 columns full brain\n",
    "brain_score_Z_matrix = np.zeros((num_files, num_channels, len(design_mat_full)))  # Preallocate matrix for weights\n",
    "\n",
    "num_files, num_channels, brain_score_Z_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 20 is out of bounds for axis 1 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_channels):\n\u001b[0;32m     11\u001b[0m     word_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 12\u001b[0m     y_j \u001b[38;5;241m=\u001b[39m \u001b[43mY\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Extract each channel\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m design_mat_cell \u001b[38;5;129;01min\u001b[39;00m design_mat_full:\n\u001b[0;32m     14\u001b[0m         X \u001b[38;5;241m=\u001b[39m design_mat_cell \n",
      "\u001b[1;31mIndexError\u001b[0m: index 20 is out of bounds for axis 1 with size 20"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, file_name in enumerate(files):\n",
    "    # Load the .mat file\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    data = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # Extract X and Y\n",
    "    Y = data['hbodata'][0:836,:] # modified to fit the new size of the design matrix\n",
    "\n",
    "    # Perform regression for each channel\n",
    "    for j in range(num_channels):\n",
    "        word_count = 0\n",
    "        y_j = Y[:, j]  # Extract each channel\n",
    "        for design_mat_cell in design_mat_full:\n",
    "            X = design_mat_cell \n",
    "            results = time_series_ridge_cv_cuda(X, y_j, device=device)  # Least squares estimation\n",
    "            brain_score_Z_matrix[i, j, word_count] = results['mean_z']  # Store weight\n",
    "            word_count += 1\n",
    "            \n",
    "    print(f\"{file_name} finished...\")\n",
    "    \n",
    "    break   # <- stop after first file\n",
    "\n",
    "# Now, W_matrix is (100, 20) containing all regression coefficients\n",
    "print(\"Regression completed. W_matrix shape:\", brain_score_Z_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_score_Z_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.savemat(\"brain_score_result_v2_TD.mat\", {\"brain_score\": brain_score_Z_matrix})\n",
    "# scipy.io.savemat(\"brain_score_result_v2_WD.mat\", {\"brain_score\": brain_score_Z_matrix})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for saving a numpy format\n",
    "# np.save(\"brain_score_result_raw.npy\", brain_score_Z_matrix)\n",
    "\"\"\"file_path=r\"F:\\MatlabBackUp\\PROJECT_HH_ENGLISH\\Pilot_Aanalysis_LLM_fNIRS\\Data\\v3_hbdata\\extracted_hbo_data_full\\TD\\story_4021.mat\"\n",
    "test=scipy.io.loadmat(file_path)\n",
    "test=test['hbodata']\n",
    "test.shape\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fnirs_nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
